{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시나리오 2.1 월간예측 (차분 & Auto_ML 사용)\n",
    "**Input 정보**\n",
    "- 데이터 셋 파일명: new_DAESANG_DATA.csv\n",
    "- 설정 옵션 파일명: input_AutoML_설정옵션.csv\n",
    "- 데이터 유형 파일명: input_AutoML_데이터유형.csv\n",
    "\n",
    "**모델정보**\n",
    "- auto_modelling\n",
    "- auto_modelling 처음 실행시 **!pip install auto_modelling** 코드 실행 필요\n",
    "\n",
    "\n",
    "**코드설명**\n",
    "- 시나리오 2-1. 월간예측 (차분 & Auto_ML 사용)\n",
    "    - 월별 RD 예측 (ID별예측, feature 조건별 예측)\n",
    "\n",
    "**Output 정보**\n",
    "- 예측 결과\n",
    "- 예측 모델 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from auto_modelling.classification import GoClassify\n",
    "from auto_modelling.regression import GoRegress\n",
    "from auto_modelling.preprocess import DataManager\n",
    "from auto_modelling.stack import Stack\n",
    "import logging\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose \n",
    "from pandas import DataFrame\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "import pmdarima\n",
    "from pmdarima import auto_arima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step1. Read data & data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_file = 'new_DAESANG_DATA.csv'\n",
    "read_col_info_file = 'input_AutoML_데이터유형.csv'\n",
    "read_model_info_file = 'input_AutoML_설정옵션.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 기본 정보\n",
    "\n",
    "- 데이터 파일 읽기\n",
    "- 모델링에 필요한 데이터 유형, 역할, 예측 주기 파라미터 값 사용자 지정 파일에서 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 파일명 입력 -> 데이터 읽기/사용자 지정 조건들 읽기 (파라미터값들)\n",
    " \n",
    " \n",
    "2. 차분만 이용/ 회귀식 선택시 -> Split Train & Test data set\n",
    "\n",
    "\n",
    "    2.1 Run 회귀식/데이터모델\n",
    "\n",
    "    2.2 결과 출력\n",
    "\n",
    "\n",
    "3. 월간 예측 전처리 (1.2) 필요/ 차분 회귀식 선택  \n",
    "\n",
    "\n",
    "    3.1 피봇/더미화 (전처리)\n",
    " \n",
    "    3.2 분석모델 실행\n",
    " \n",
    "    3.3 결과 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_info (read_data_file, read_col_info_file, read_model_info_file):\n",
    "    # input data\n",
    "    data = pd.read_csv(read_data_file) # 년도와 월을 split해서 new data 생성\n",
    "\n",
    "    # col info\n",
    "    col_info = data.iloc[0] # col 정보 ex. int / str / month_no / ...\n",
    "    dummy_list = col_info.loc[col_info=='STR'].index.tolist() # str부분 더미화처리해야함\n",
    "    id_val = col_info.loc[col_info=='STR_KEY'].index.tolist()[0] # key는 자동으로 id 인식\n",
    "\n",
    "    # input role info\n",
    "    role_info = pd.read_csv(read_col_info_file, encoding ='cp949') # 모델링 할 때 사용할 x, y, month\n",
    "    x_val = role_info.loc[role_info['Role']=='x', 'col_name'].tolist() # x변수 다중리스트형태\n",
    "    y_val = role_info.loc[role_info['Role']=='y', 'col_name'].tolist()[0] # y변수는 단일\n",
    "    month_val = role_info.loc[role_info['예측주기']=='p', 'col_name'].tolist()[0] # month값은 단일\n",
    "\n",
    "    # input model info 모델과 예측달 정하기\n",
    "    model_info = pd.read_csv(read_model_info_file)\n",
    "    model_name = model_info['Model'][0] # 기본으로 auto 지정\n",
    "    month_name = model_info['예측월'][0] # 예측하고 싶은 월 예:) 3월 QTY예측 / 10월 QTY 예측\n",
    "    # 맨처음 month로 불러온 것과 동일하게 이름작성 필수 ex. Mar (o) / March (X) / 3 (X)\n",
    "\n",
    "    # data split\n",
    "    Train = data[data['DATA_TYPE']=='TD'] # 학습할 데이터\n",
    "    Train[[y_val]] = Train[[y_val]].fillna(0).astype('int32') # 학습할 데이터\n",
    "    Predict = data[data['DATA_TYPE']=='RD'] # 예측해야할 데이터 \n",
    "    Predict[[y_val]] = Predict[[y_val]].fillna(0).astype('int32')\n",
    "    \n",
    "    return dummy_list, x_val, y_val, id_val, month_val, Train, Predict, model_name, month_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 전처리 과정 \n",
    "- 월간예측을 위한 전처리 과정\n",
    "- 예측하고 싶은 달에 대한 예측값 출력을 위한 전처리 과정\n",
    "- 완성된 Train, Predict data를 각각 role에 따라 분리한 후 col정보에 따른 더미화 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_df (dummy_list, x_val, y_val, id_val, month_val, Train, Predict, month_name):\n",
    "    \n",
    "    # part(id)에 따른 X, y train 할 값들 - 피봇이용해서 만들기\n",
    "    X_Train = pd.pivot_table(Train, index=id_val,values=x_val, aggfunc='first') # id에 따른 x 값 # 제품간 feature는 동일하므로 첫번째 값 출력\n",
    "    y_Train = pd.pivot_table(Train, index=id_val, columns=month_val, values=y_val, aggfunc = np.mean, fill_value = 0) # id에 따른 월별 예측을 위해 월별 평균/ 결측값은 0처리\n",
    "    X_Predict = pd.pivot_table(Predict, index=id_val,values=x_val, aggfunc='first') # Train과 col은 항상 일치해야함\n",
    "    #  y_Predict는 현재 없음, 있다면 실측값과 예측값을 비교해서 정확도 및 mse 확인 가능\n",
    "    y_Predict = pd.pivot_table(Predict, index=id_val, columns=month_val, values=y_val, aggfunc = np.mean, fill_value = 0)\n",
    "    \n",
    "    # 월별 qty를 위해 분리 # 모델불러올 때 예측하고 싶은 달 불러 올 것 - 아래참고\n",
    "    mons = []\n",
    "    for i in range(len(y_Train.columns)):\n",
    "        mon = pd.DataFrame(y_Train.iloc[:,i])\n",
    "        mons.append(mon)\n",
    "    for month in mons:\n",
    "        if month.columns == month_name:\n",
    "            month_df = pd.DataFrame(month)\n",
    "    # 즉, month가 예측하고 싶은 달이 됨\n",
    "\n",
    "    # 따라서 y_Train을 예측하고 싶은 것으로 재설정\n",
    "    y_Train = month_df # 월 QTY\n",
    "    \n",
    "    # y_Predict를 위해 같은 과정을 한번 더 해줌\n",
    "    mons2 = []\n",
    "    for i in range(len(y_Predict.columns)):\n",
    "        mon2 = pd.DataFrame(y_Predict.iloc[:,i])\n",
    "        mons2.append(mon2)\n",
    "    for month2 in mons2:\n",
    "        if month2.columns == month_name:\n",
    "            month2_df = pd.DataFrame(month2)\n",
    "\n",
    "    y_Predict = month2_df # 월 QTY\n",
    "    \n",
    "    # 더미화 할 col정보\n",
    "    ele = [x for x in dummy_list if x in X_Train] # 더미화가 필요한 col중에 train에 들어가지 않는 것이 있을 수 있으므로 진행\n",
    "\n",
    "    # 더미화 형태의 X로 바꿈\n",
    "    X_Train = pd.get_dummies(data=X_Train, columns=ele)\n",
    "    X_Predict = pd.get_dummies(data=X_Predict, columns=ele)\n",
    "\n",
    "    return X_Train, y_Train, X_Predict, y_Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step2. 빠른 연산을 위한 단계 (선택사항) -> 전체 데이터로 모델링할시 step3로 이동\n",
    "\n",
    "- 파일 정보를 불러와 일부샘플을 뽑은 뒤 차분계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빠른 결과값을 위해 일부로만 샘플진행\n",
    "train_num = 300\n",
    "test_num = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_sample(train_num, test_num, X_Train, X_Predict, y_Train, y_Predict):\n",
    "    \n",
    "    # 빠른 결과값을 위해 일부로만 샘플진행\n",
    "    X_Train = X_Train.head(train_num) # 300개\n",
    "    X_Predict = X_Predict[round(X_Predict.shape[0]/2) : round(X_Predict.shape[0]/2) + test_num] # 50개\n",
    "\n",
    "    # 예측하고 싶은 월을 y로 둠\n",
    "    y_Train = y_Train.head(train_num)\n",
    "    y_Predict = y_Predict[round(y_Predict.shape[0]/2) : round(y_Predict.shape[0]/2) + test_num] \n",
    "\n",
    "    return X_Train, y_Train, X_Predict, y_Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step3. 차분계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 에 대한 차분계산\n",
    "def get_subtract_sample(x):\n",
    "    x = x.transpose()\n",
    "    dff = pd.DataFrame()\n",
    "    for i in range(len(x.columns)):\n",
    "        for j in range(i+1,len(x.columns)):\n",
    "            var = str(x.columns[i]) + '-' + str(x.columns[j])\n",
    "            dff[var] = abs(x.iloc[:,i].astype('int32')-x.iloc[:,j].astype('int32'))\n",
    "            \n",
    "    temp_train_x = pd.DataFrame(data=dff)\n",
    "    #temp_train_x_0 = temp_train_x.fillna(0)\n",
    "    \n",
    "    return temp_train_x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data (X_Predict) 와 X_Train의 차분 계산\n",
    "def subtract (new_test_df,train_df):\n",
    "    dff = pd.DataFrame()\n",
    "    for i in range(len(new_test_df.columns)):\n",
    "        for j in range(len(train_df.columns)):\n",
    "            var = str(new_test_df.columns[i]) + '-' + str(train_df.columns[j])\n",
    "            dff[var] = abs(new_test_df.iloc[:,i].astype('int32')-train_df.iloc[:,j].astype('int32'))\n",
    "    \n",
    "    temp_train_x = pd.DataFrame(data=dff)\n",
    "    \n",
    "    return temp_train_x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 차분 계산\n",
    "def get_diff_df(train_num, test_num, X_Train, X_Predict, y_Train, y_Predict):\n",
    "    \n",
    "    # [차분 과정1.] 회귀식을 위한 데이터 준비 \n",
    "    X_Train_df = get_subtract_sample(X_Train) # 학습 데이터 차분 (subtracting inside) (row1 - row0)\n",
    "    X_Predict_df = subtract(X_Predict.T, X_Train.T) # 예측 데이터셋을 위한 차분  (df1[row1] - df2[row1])\n",
    "    y_Train_df = get_subtract_sample(y_Train) # 학습 데이터 y 에 대한 차분 (y[row1] - y[row0])\n",
    "    y_Predict_df = subtract(y_Predict.T, y_Train.T)\n",
    "    # 알아보기 쉽게 이름 재 구성 _df를 제외하고 사용해야 일반회귀모델링과 같은 main함수 사용가능\n",
    "    \n",
    "    return X_Train_df, y_Train_df, X_Predict_df, y_Predict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step4. 파일 저장경로 및 파일 저장정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_var(df,Model_ver):  #모델버전 생성 \n",
    "    df = df.reset_index(drop=False)\n",
    "    Model_ver_list =  [Model_ver] * len(df)\n",
    "    Model_ver_list = pd.DataFrame(Model_ver_list, columns =['모델 버전'])\n",
    "    \n",
    "    updated_df = pd.concat([Model_ver_list,df] ,axis=1)\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "def outputfile(sheet1,output_file_name):     \n",
    "    sheet1.to_csv(output_file_name, encoding ='utf-8-sig')\n",
    "    print(\"\\n폴더에서\",output_file_name,\"파일을 확인하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_match_prediction(y_pred_df):\n",
    "    indexs = pd.DataFrame(y_pred_df.index.str.split('-',1).tolist(),\n",
    "                                 columns = ['RD_index','TD_index'])\n",
    "    y_pred_df_ = y_pred_df.reset_index(drop=True)\n",
    "    result = pd.concat([indexs,y_pred_df_], axis=1)\n",
    "    return result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_results(model, X_Predict_df, y_val): # 식 결과 export into excel\n",
    "    model_results = model.summary()\n",
    "\n",
    "    model_info = model_results.tables[0].as_html()\n",
    "    model_info = pd.read_html(model_info, header=0, index_col=0)[0]\n",
    "    \n",
    "    model_result = model_results.tables[1].as_html()\n",
    "    model_result = pd.read_html(model_result, header=0, index_col=0)[0] # Excel 내보내기\n",
    "    \n",
    "#     return model_info, model_result\n",
    "    Model_ver = model_info[y_val][0] + \"_\" + model_info[y_val][1] + \"_\"+model_info[y_val][2]\n",
    "   \n",
    "    model_info_df = get_model_var(model_info,Model_ver)\n",
    "    model_result_df = get_model_var(model_result,Model_ver)\n",
    "    \n",
    "    prediction = model.predict(X_Predict_df) # 예측값구하는 식\n",
    "    prediction_df = pd.DataFrame(data=prediction)\n",
    "    prediction_df.columns = ['Predicted']\n",
    "    prediction_df.index = X_Predict_df.index\n",
    "    \n",
    "    \n",
    "    results_pred_df = index_match_prediction(prediction_df)\n",
    "    # results_pred_df_= get_model_var(prediction_df, Model_ver)\n",
    "\n",
    "    outputfile(results_pred_df, '_모델_예측결과.csv') # 예측값 엑셀로 내보내기\n",
    "    outputfile(model_info_df,'_모델_정보.csv') # 모델 정보 엑셀로 내보내기\n",
    "    outputfile(model_result_df,'_모델_결과.csv') # 모델 식 엑셀로 내보내기\n",
    "    \n",
    "    return model_info_df,model_result_df,Model_ver,results_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 출력\n",
    "def get_model_results (model, X_Predict_df):\n",
    "\n",
    "    Model_ver = pd.DataFrame([str(model)], columns=['모델정보'])\n",
    "    \n",
    "    prediction = model.predict(X_Predict_df) # 예측값구하는 식\n",
    "    prediction_df = pd.DataFrame(data=prediction)\n",
    "    prediction_df.columns = ['Predicted']\n",
    "    prediction_df.index = X_Predict_df.index\n",
    "    \n",
    "    results_pred_df = index_match_prediction(prediction_df)\n",
    "    # results_pred_df_= get_model_var(prediction_df, Model_ver)    \n",
    "    \n",
    "    outputfile(Model_ver,'output_AutoML_정보.csv')\n",
    "    outputfile(results_pred_df,'output_AutoML_예측결과.csv')\n",
    "    \n",
    "        \n",
    "    return Model_ver, results_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model select\n",
    "def main():\n",
    "    \n",
    "    # 데이터 분리\n",
    "    dummy_list, x_val, y_val, id_val, month_val, Train, Predict, model_name, month_name = read_data_info (read_data_file, read_col_info_file, read_model_info_file)\n",
    "    X_Train_df, y_Train_df, X_Predict_df, y_Predict_df = make_model_df (dummy_list, x_val, y_val, id_val, month_val, Train, Predict, month_name)\n",
    "    \n",
    "    # 샘플뽑아 진행 (생략가능)\n",
    "    X_Train_df, y_Train_df, X_Predict_df, y_Predict_df = small_sample(train_num, test_num, X_Train_df, X_Predict_df, y_Train_df, y_Predict_df)\n",
    "    X_Train_df, y_Train_df, X_Predict_df, y_Predict_df = get_diff_df(train_num, test_num, X_Train_df, X_Predict_df, y_Train_df, y_Predict_df)\n",
    "    \n",
    "    # 세가지는 일반 모델 직접 불러올 수 있도록 샘플링\n",
    "    # 예시\n",
    "    if model_name == 'logit':\n",
    "        model = sm.Logit(y_Train_df, X_Train_df).fit() \n",
    "        get_simple_results(model, y_Predict_df, X_Predict_df, y_val)\n",
    "\n",
    "    elif model_name == 'OLS':\n",
    "        model = sm.OLS(y_Train_df, X_Train_df).fit()\n",
    "        get_simple_results(model, y_Predict_df, X_Predict_df, y_val)\n",
    "        \n",
    "    elif model_name == 'MNlogit':\n",
    "        model = sm.MNLogit(y_Train_df, X_Train_df).fit() \n",
    "        get_simple_results(model, y_Predict_df, X_Predict_df, y_val)\n",
    "    \n",
    "    elif model_name == 'Random_fore':\n",
    "        model = RandomForestRegressor(max_depth=2, random_state=0).fit(X_Train_df, y_Train_df) \n",
    "        get_model_results (model, X_Predict_df)\n",
    "        \n",
    "    # 현재 우리가 필요한 문제 auto_reg로 자동화 회귀모델링\n",
    "    # auto 모델의 경우 predict를 할 수 있는 reg와 분류작업을 위한 classifi를 직접 지정받아야하는 부분입니다. \n",
    "    elif model_name == 'Auto_classi':\n",
    "        model =  GoClassify(n_best=1).train(X_Train_df, y_Train_df)\n",
    "        get_model_results (model, X_Predict_df)\n",
    "        \n",
    "    elif model_name == 'Auto_reg':\n",
    "        model =  GoRegress(n_best=1).train(X_Train_df, y_Train_df)\n",
    "        get_model_results (model, X_Predict_df)\n",
    "        \n",
    "    else: \n",
    "        print('Please select your data model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kstec\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3418: DtypeWarning: Columns (2,5,6,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\Kstec\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "INFO:auto_modelling.regression:Starting to train models\n",
      "INFO:auto_modelling.regression:Starting to train with ExtraTreesRegressor\n",
      "C:\\Users\\Kstec\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "INFO:auto_modelling.regression:==============================================\n",
      "INFO:auto_modelling.regression:The current best result is -32900733.07291886\n",
      "INFO:auto_modelling.regression:with ExtraTreesRegressor(max_features=0.3, min_samples_leaf=11, min_samples_split=15)\n",
      "INFO:auto_modelling.regression:==============================================\n",
      "INFO:auto_modelling.regression:Starting to train with GradientBoostingRegressor\n",
      "C:\\Users\\Kstec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "INFO:auto_modelling.regression:==============================================\n",
      "INFO:auto_modelling.regression:The current best result is -32685056.430233393\n",
      "INFO:auto_modelling.regression:with GradientBoostingRegressor(alpha=0.85, learning_rate=0.5, max_depth=1,\n",
      "                          max_features=0.35000000000000003, min_samples_leaf=12,\n",
      "                          subsample=0.7500000000000001)\n",
      "INFO:auto_modelling.regression:==============================================\n",
      "INFO:auto_modelling.regression:Starting to train with AdaBoostRegressor\n",
      "C:\\Users\\Kstec\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "INFO:auto_modelling.regression:==============================================\n",
      "INFO:auto_modelling.regression:The current best result is -32685056.430233393\n",
      "INFO:auto_modelling.regression:with GradientBoostingRegressor(alpha=0.85, learning_rate=0.5, max_depth=1,\n",
      "                          max_features=0.35000000000000003, min_samples_leaf=12,\n",
      "                          subsample=0.7500000000000001)\n",
      "INFO:auto_modelling.regression:==============================================\n",
      "INFO:auto_modelling.regression:Starting to train with DecisionTreeRegressor\n",
      "INFO:auto_modelling.regression:==============================================\n",
      "INFO:auto_modelling.regression:The current best result is -32685056.430233393\n",
      "INFO:auto_modelling.regression:with GradientBoostingRegressor(alpha=0.85, learning_rate=0.5, max_depth=1,\n",
      "                          max_features=0.35000000000000003, min_samples_leaf=12,\n",
      "                          subsample=0.7500000000000001)\n",
      "INFO:auto_modelling.regression:==============================================\n",
      "INFO:auto_modelling.regression:Starting to train with KNeighborsRegressor\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
